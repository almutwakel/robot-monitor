Project: Manipulation Uncertainty
Purpose: Analyzing prediction uncertainty in video-language and vision-language models

Key Components:
- Video-Language Models (VideoClip, Frozen-in-Time, CLIP4Clip)
- Vision-Language Models (CLIP, BLIP, Florence)
- Uncertainty estimation through:
  * Temperature scaling for calibrated confidence scores
  * Attention visualization
  * Confidence thresholding

Important Notes:
- Project initialized on: [Current Date]
- Focus on multimodal models (video+text, image+text)
- Key metrics: prediction confidence, attention distribution
- Consider both zero-shot and fine-tuned scenarios

Implementation Strategy:
1. Model loading and inference pipeline
2. Confidence score calculation and calibration
3. Attention visualization for uncertainty analysis
4. Evaluation across different domains/tasks
